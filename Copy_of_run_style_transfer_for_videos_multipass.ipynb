{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [
        "Vz0I_aD-7cAE",
        "I6hEJV088iqB"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ThroughIris/STARVE/blob/master/Copy_of_run_style_transfer_for_videos_multipass.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vz0I_aD-7cAE"
      },
      "source": [
        "# Clone Our GitHub Repo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8zZSre07O-g",
        "outputId": "2d8556ba-c12c-425e-afdb-c4914c7924bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd /content/\n",
        "!git clone https://github.com/ThroughIris/STARVE.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'STARVE'...\n",
            "remote: Enumerating objects: 1014, done.\u001b[K\n",
            "remote: Counting objects: 100% (91/91), done.\u001b[K\n",
            "remote: Compressing objects: 100% (74/74), done.\u001b[K\n",
            "remote: Total 1014 (delta 40), reused 37 (delta 17), pack-reused 923\u001b[K\n",
            "Receiving objects: 100% (1014/1014), 135.75 MiB | 34.15 MiB/s, done.\n",
            "Resolving deltas: 100% (589/589), done.\n",
            "Updating files: 100% (1300/1300), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6hEJV088iqB"
      },
      "source": [
        "# Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpLrbk8M8gWY",
        "outputId": "f0f50174-b10a-4edc-bb83-738c56d4c45f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install tensorflow_addons\n",
        "!sudo apt-get install libgoogle-glog-dev  # When using GPU backend\n",
        "!echo /content/STARVE/opticFlow/web_gpudm_1.0_compiled/caffe/.build_release/lib > /etc/ld.so.conf.d/caffe.conf\n",
        "!ldconfig\n",
        "!pip install moviepy\n",
        "!pip install imageio-ffmpeg\n",
        "!pip install --upgrade imageio\n",
        "!pip install --upgrade moviepy\n",
        "#!pip install pip==19.0.2 wheel==0.33.0 \\\n",
        "#&& pip install imageio-ffmpeg==0.2.\n",
        "\n",
        "#!pip install imageio-ffmpeg --no-binary\n",
        "#!pip install ffmpeg  # or equivalent"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.19.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow_addons) (23.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow_addons) (2.7.1)\n",
            "Installing collected packages: tensorflow_addons\n",
            "Successfully installed tensorflow_addons-0.19.0\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libgflags-dev libgflags2.2 libgoogle-glog0v5\n",
            "The following NEW packages will be installed:\n",
            "  libgflags-dev libgflags2.2 libgoogle-glog-dev libgoogle-glog0v5\n",
            "0 upgraded, 4 newly installed, 0 to remove and 22 not upgraded.\n",
            "Need to get 303 kB of archives.\n",
            "After this operation, 1,566 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 libgflags2.2 amd64 2.2.2-1build1 [78.0 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal/universe amd64 libgflags-dev amd64 2.2.2-1build1 [96.6 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu focal/universe amd64 libgoogle-glog0v5 amd64 0.4.0-1build1 [51.5 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu focal/universe amd64 libgoogle-glog-dev amd64 0.4.0-1build1 [76.4 kB]\n",
            "Fetched 303 kB in 0s (699 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 4.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libgflags2.2.\n",
            "(Reading database ... 128216 files and directories currently installed.)\n",
            "Preparing to unpack .../libgflags2.2_2.2.2-1build1_amd64.deb ...\n",
            "Unpacking libgflags2.2 (2.2.2-1build1) ...\n",
            "Selecting previously unselected package libgflags-dev.\n",
            "Preparing to unpack .../libgflags-dev_2.2.2-1build1_amd64.deb ...\n",
            "Unpacking libgflags-dev (2.2.2-1build1) ...\n",
            "Selecting previously unselected package libgoogle-glog0v5.\n",
            "Preparing to unpack .../libgoogle-glog0v5_0.4.0-1build1_amd64.deb ...\n",
            "Unpacking libgoogle-glog0v5 (0.4.0-1build1) ...\n",
            "Selecting previously unselected package libgoogle-glog-dev.\n",
            "Preparing to unpack .../libgoogle-glog-dev_0.4.0-1build1_amd64.deb ...\n",
            "Unpacking libgoogle-glog-dev (0.4.0-1build1) ...\n",
            "Setting up libgflags2.2 (2.2.2-1build1) ...\n",
            "Setting up libgflags-dev (2.2.2-1build1) ...\n",
            "Setting up libgoogle-glog0v5 (0.4.0-1build1) ...\n",
            "Setting up libgoogle-glog-dev (0.4.0-1build1) ...\n",
            "Processing triggers for libc-bin (2.31-0ubuntu9.9) ...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.8/dist-packages (0.2.3.5)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.8/dist-packages (from moviepy) (4.64.1)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.8/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.1.2 in /usr/local/lib/python3.8/dist-packages (from moviepy) (2.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from moviepy) (1.22.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from imageio<3.0,>=2.1.2->moviepy) (8.4.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting imageio-ffmpeg\n",
            "  Downloading imageio_ffmpeg-0.4.8-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: imageio-ffmpeg\n",
            "Successfully installed imageio-ffmpeg-0.4.8\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.8/dist-packages (2.9.0)\n",
            "Collecting imageio\n",
            "  Downloading imageio-2.26.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.8/dist-packages (from imageio) (8.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from imageio) (1.22.4)\n",
            "Installing collected packages: imageio\n",
            "  Attempting uninstall: imageio\n",
            "    Found existing installation: imageio 2.9.0\n",
            "    Uninstalling imageio-2.9.0:\n",
            "      Successfully uninstalled imageio-2.9.0\n",
            "Successfully installed imageio-2.26.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.8/dist-packages (0.2.3.5)\n",
            "Collecting moviepy\n",
            "  Downloading moviepy-1.0.3.tar.gz (388 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.3/388.3 KB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.8/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.8/dist-packages (from moviepy) (4.64.1)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from moviepy) (2.25.1)\n",
            "Collecting proglog<=1.0.0\n",
            "  Downloading proglog-0.1.10-py3-none-any.whl (6.1 kB)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from moviepy) (1.22.4)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.8/dist-packages (from moviepy) (2.26.0)\n",
            "Requirement already satisfied: imageio_ffmpeg>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from moviepy) (0.4.8)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.8/dist-packages (from imageio<3.0,>=2.5->moviepy) (8.4.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0,>=2.8.1->moviepy) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0,>=2.8.1->moviepy) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.10)\n",
            "Building wheels for collected packages: moviepy\n",
            "  Building wheel for moviepy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for moviepy: filename=moviepy-1.0.3-py3-none-any.whl size=110742 sha256=d38ef12a3cfe640c95f5f7c3207a463fded0b4511684c63cef3ed3d0c07f37ff\n",
            "  Stored in directory: /root/.cache/pip/wheels/e4/a4/db/0368d3a04033da662e13926594b3a8cf1aa4ffeefe570cfac1\n",
            "Successfully built moviepy\n",
            "Installing collected packages: proglog, moviepy\n",
            "  Attempting uninstall: moviepy\n",
            "    Found existing installation: moviepy 0.2.3.5\n",
            "    Uninstalling moviepy-0.2.3.5:\n",
            "      Successfully uninstalled moviepy-0.2.3.5\n",
            "Successfully installed moviepy-1.0.3 proglog-0.1.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioGnhE-D7hag"
      },
      "source": [
        "# Run the Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u195I-qo9TwC"
      },
      "source": [
        "## Run a Single Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSEWRZae9kpZ"
      },
      "source": [
        "In `hyperparams/dataset_param.py`, \n",
        "*   set `use_video = False`\n",
        "*   set `content_img_path`\n",
        "*   set `style_img_path`\n",
        "\n",
        "The stylized image will be saved in `output/`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TskmbBH29ZMT"
      },
      "source": [
        "## Run a Video"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i55E51nl9flh"
      },
      "source": [
        "In `hyperparams/dataset_param.py`, \n",
        "*   set `use_video = True`\n",
        "*   set `video_path`\n",
        "*   set `style_img_path`\n",
        "*   set `video_fps`\n",
        "\n",
        "The stylized video will be saved in `output/`.\n",
        "\n",
        "Furthermore, follow the instructions below to use specific losses.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUTQZr0y9cbT"
      },
      "source": [
        "### Content Loss + Style Loss + Total Variation (TV) Loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46q-_Amm_tde"
      },
      "source": [
        "In `hyperparams/train_param.py`,\n",
        "*   set `n_step = 150`\n",
        "*   set `n_passes = 1`\n",
        "*   set `use_optic_flow = False`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeiHDMEqAgIa"
      },
      "source": [
        "### Content Loss + Style Loss + TV Loss + Short-Term Temporal Loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLk0sYLnBDis"
      },
      "source": [
        "In `hyperparams/train_param.py`,\n",
        "*   set `n_step = 150`\n",
        "*   set `n_passes = 1`\n",
        "*   set `use_optic_flow = True`\n",
        "*   set `use_deep_matching_gpu = True`\n",
        "\n",
        "In `hyperparams/dataset_param.py`,\n",
        "*   set `init_generated_image_method = 'image_flow_warp'`\n",
        "\n",
        "In `hyperparams/loss_param.py`,\n",
        "*   set `J = [1]`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-uSnJP2BeFV"
      },
      "source": [
        "### Content Loss + Style Loss + TV Loss + Long-Term Temporal Loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUXJ-hXsBiuA"
      },
      "source": [
        "In `hyperparams/train_param.py`,\n",
        "*   set `n_step = 150`\n",
        "*   set `n_passes = 1`\n",
        "*   set `use_optic_flow = True`\n",
        "*   set `use_deep_matching_gpu = True`\n",
        "\n",
        "In `hyperparams/dataset_param.py`,\n",
        "*   set `init_generated_image_method = 'image_flow_warp'`\n",
        "\n",
        "In `hyperparams/loss_param.py`,\n",
        "*   set `J = [1, 10, 20, 40]`, or any list of integers with more than one element"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01pnwdycCthJ"
      },
      "source": [
        "### Content Loss + Style Loss + TV Loss + Multi-Pass (Short-Term Temporal Loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUgWwtonC0dX"
      },
      "source": [
        "In `hyperparams/train_param.py`,\n",
        "*   set `n_step = 10`, or any integer > 1, `n_step` * `n_passes` is the total number of iterations\n",
        "*   set `n_passes = 15`, or any integer > 1, `n_step` * `n_passes` is the total number of iterations\n",
        "*   set `use_optic_flow = True`\n",
        "*   set `use_deep_matching_gpu = True`\n",
        "\n",
        "In `hyperparams/dataset_param.py`,\n",
        "*   set `init_generated_image_method = 'image'`\n",
        "\n",
        "In `hyperparams/loss_param.py`,\n",
        "*   set `use_temporal_pass = 8`, or any integer > 0, indicating from which pass to use short-term temporal loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RhuymdR7mG8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06b78488-d881-4751-a61a-dd227229ab8c"
      },
      "source": [
        "%cd /content/STARVE/\n",
        "!python main.py"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/STARVE\n",
            "2023-03-07 23:17:16.786169: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-07 23:17:18.580062: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-07 23:17:18.580284: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-07 23:17:18.580313: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Convert video to frames: 577it [00:18, 31.86it/s]\n",
            "2023-03-07 23:17:41.875711: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "[pass 1/1 | frame 1/577 1.jpg]:   0% 0/10 [00:00<?, ?it/s]2023-03-07 23:18:19.295356: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 2123366400 exceeds 10% of free system memory.\n",
            "[pass 1/1 | frame 1/577 1.jpg]:  10% 1/10 [00:22<03:21, 22.44s/it]2023-03-07 23:18:39.899592: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 2123366400 exceeds 10% of free system memory.\n",
            "[pass 1/1 | frame 1/577 1.jpg]:  20% 2/10 [00:42<02:50, 21.25s/it]2023-03-07 23:18:59.166759: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 2123366400 exceeds 10% of free system memory.\n",
            "[pass 1/1 | frame 1/577 1.jpg]:  30% 3/10 [01:02<02:22, 20.32s/it]2023-03-07 23:19:18.969680: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 2123366400 exceeds 10% of free system memory.\n",
            "[pass 1/1 | frame 1/577 1.jpg]:  40% 4/10 [01:21<02:00, 20.16s/it]2023-03-07 23:19:37.863842: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 2123366400 exceeds 10% of free system memory.\n",
            "[pass 1/1 | frame 1/577 1.jpg]: 100% 10/10 [03:17<00:00, 19.74s/it]\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
            "[pass 1/1 | frame 2/577 2.jpg]:  90% 9/10 [03:10<00:21, 21.21s/it]\n",
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 168, in <module>\n",
            "    train()\n",
            "  File \"main.py\", line 90, in train\n",
            "    loss_dict = tf_train_step(model, generated_image, optimizer, content_target, style_target,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 880, in __call__\n",
            "    result = self._call(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 912, in _call\n",
            "    return self._no_variable_creation_fn(*args, **kwds)  # pylint: disable=not-callable\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\", line 134, in __call__\n",
            "    return concrete_function._call_flat(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\", line 1745, in _call_flat\n",
            "    return self._build_call_outputs(self._inference_function.call(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\", line 378, in call\n",
            "    outputs = execute.execute(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\", line 52, in quick_execute\n",
            "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGT7PJncw-Sf",
        "outputId": "96c5840b-462e-4e9a-9d19-5ccbf6afa95b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xy8ZLwkWPpCz"
      },
      "source": [
        "### Delete a folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rI4aqEXuPoQ5"
      },
      "source": [
        "!rm -rf *path*\n",
        "# eg. !rm -rf output/optic_flow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mx3SvdSOwFJ"
      },
      "source": [
        "### Download files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Jxs6mipMMAP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "cad7bbf2-8d96-468c-955b-aa27b2a153f5"
      },
      "source": [
        "from google.colab import files\n",
        "#If need to zip folder: \n",
        "!zip -r *file_name*.zip . -i *file_path*\n",
        "## eg. !zip -r multipass-output.zip output\n",
        "\n",
        "#Download \n",
        "files.download('*file_name*') #files.download('multipass-output.zip')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tzip warning: zip file empty\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-73c433fdb0d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#Download\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'*file_name*'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#files.download('multipass-output.zip')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    207\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Cannot find file: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=undefined-variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m   \u001b[0mcomm_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_IPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomm_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Cannot find file: *file_name*"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJiFYn0MNHy2"
      },
      "source": [
        "## Run fast neural style transfer "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4DZ7Ry23lw-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecf369b9-6cdb-467c-8874-cd047bc600be"
      },
      "source": [
        "%cd /content/STARVE/\n",
        "!python main_fast.py"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/STARVE\n",
            "2023-03-06 23:59:45.670007: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-06 23:59:47.440706: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-06 23:59:47.440857: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-06 23:59:47.440878: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Convert video to frames: 635it [00:18, 33.96it/s]\n",
            "2023-03-07 00:00:11.035502: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Moviepy - Building video output/stylized_CaseStudy01_Chasing_the_feeling_v016.mp4.\n",
            "Moviepy - Writing video output/stylized_CaseStudy01_Chasing_the_feeling_v016.mp4\n",
            "\n",
            "Moviepy - Done !\n",
            "Moviepy - video ready output/stylized_CaseStudy01_Chasing_the_feeling_v016.mp4\n"
          ]
        }
      ]
    }
  ]
}